# 使用Ollama本地离线体验SimpleRAG（手把手教程）

## Ollama介绍

Ollama是一个开源项目，专注于开发和部署大语言模型，特别是像LLaMA这样的模型，用于生成高质量的文本和进行复杂的自然语言处理任务。Ollama的目标是让大语言模型的运行和使用变得更加容易和普及，而无需复杂的基础设施或深度的机器学习知识。

![image-20240822110024317](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822110024317.png)

GitHub地址：https://github.com/ollama/ollama

## RAG是什么？

检索生成增强（Retrieval-Augmented Generation，RAG）是一种结合了检索（Retrieval）和生成（Generation）两种技术的自然语言处理方法，主要用于改进文本生成任务的性能，如问答系统、对话系统、文本摘要和文档生成等。RAG模型通过在生成模型的基础上，引入一个检索模块，来增强生成模型的准确性和丰富性。

在传统的生成模型中，模型完全依赖于训练数据中学习到的模式和统计信息来生成文本，这可能导致生成的内容缺乏新颖性或准确性。而检索模块则可以从外部知识库或文档中检索相关的信息，将这些信息作为额外的输入，提供给生成模型，从而帮助生成更准确、更丰富和更具体的文本。

具体来说，RAG模型的工作流程如下：

1. **检索阶段**：模型首先根据输入的查询或上下文，从外部知识库中检索出与之最相关的文档或片段。
2. **融合阶段**：检索到的信息与输入的查询或上下文进行融合，形成增强的输入。
3. **生成阶段**：增强后的输入被送入生成模型，生成模型根据这些信息生成最终的文本输出。

通过这种方式，RAG模型能够在生成过程中利用到外部知识，提高了生成文本的准确性和丰富性，同时也增强了模型的可解释性，因为生成的文本可以追溯到具体的来源。RAG模型在处理需要大量领域知识或具体事实信息的任务时，表现出了显著的优势。

## SimpleRAG介绍

A simple RAG demo based on WPF and Semantic Kernel.

SimpleRAG是基于WPF与Semantic Kernel实现的一个简单的RAG应用，可用于学习与理解如何使用Semantic Kernel构建一个简单的RAG应用。

![image-20240822100239041](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822100239041.png)

GitHub地址：https://github.com/Ming-jiayou/SimpleRAG

### 主要功能

**AI聊天**

支持所有兼容OpenAI格式的大语言模型：

![image-20240819163701855](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240819163701855.png)

**文本嵌入**

支持所有兼容OpenAI格式的嵌入模型：

![image-20240819163900106](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240819163900106.png)

**简单的RAG回答**

简单的RAG回答效果：

![image-20240819164221306](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240819164221306.png)

对比不使用RAG的回答：

![image-20240819164322893](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240819164322893.png)

## 使用Ollama本地离线体验SimpleRAG

来到SimpleRAG的GitHub参考，注意到这里有个Releases：

![image-20240822100649148](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822100649148.png)

点击SimpleRAG-v0.0.1，有两个压缩包，一个依赖net8.0-windows框架，一个独立：

![image-20240822100817138](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822100817138.png)

依赖框架的包会小一些，独立的包会大一些，如果你的电脑已经装了net8.0-windows框架可以选择依赖框架的包，考虑到可能大部分人不一定装了net8.0-windows框架，我以独立的包做演示，点击压缩包，就在下载了：

![image-20240822101244281](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822101244281.png)

解压该压缩包：

![image-20240822101450182](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822101450182.png)

打开appsettings.json文件：

![image-20240822101600329](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822101600329.png)

appsettings.json文件如下所示：

![image-20240822101740892](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822101740892.png)

在你的电脑上启动Ollama，在命令行中输入ollama list 查看已经下载的模型：

![image-20240822113619155](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822113619155.png)

由于我电脑的配置不是很好，对话模型以gemma2:2b为例，嵌入模型以bge-m3:latest为例，appsettings.json文件这样写：

![image-20240822113903239](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822113903239.png)

Endpoint输入Ollama的地址，默认是http://localhost:11434，Ollama不需要Api Key随便写。

现在点击SimpleRAG.exe即可运行程序：

![image-20240822102117959](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822102117959.png)

程序运行之后，如下所示：

![image-20240822102215516](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822102215516.png)

先通过AI聊天测试配置是否成功：

![image-20240822114300380](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822114300380.png)

配置已经成功。

现在来测试一下嵌入。

先拿一个简单的文本进行测试：

```csharp
小k最喜欢的编程语言是C#。
```

![image-20240822114549483](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822114549483.png)

嵌入成功：

![image-20240822114618014](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822114618014.png)

这个Demo程序为了方便存储文本向量使用的是Sqlite数据库，在这里可以看到：

![image-20240822102554159](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822102554159.png)

如果你有数据库管理软件的话，打开该数据库，会发现文本已经以向量的形式存入Sqlite数据库中：

![image-20240822114904572](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822114904572.png)

现在开始测试RAG回答效果：

![image-20240822115055457](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822115055457.png)

对比不使用RAG的回答效果：

![image-20240822115204218](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822115204218.png)

可以发现大语言模型根本不知道我们想问的私有数据的事情。

现在我们可以来测试一下更复杂一点的文本了：

```csharp
过去一年，在大语言模型浪潮之下，人形机器人成为市场上为数不多的热门赛道。但在日前举行的世界机器人大会期间，杭州宇树科技有限公司(以下简称“宇树科技”）创始人、CEO王兴兴向包括澎湃科技在内的媒体直言， 人形机器人最大的问题其实和大模型相似，整个机器人AI模型水平能力不够，行业的热度超过了行业的落地能力。在资本热潮之下，机器人行业已经出现了估值过高等乱象，他们仍将坚持四足机器人和人形机器人 “两条腿”走路，对AI保持克制。

此次世界机器人大会，宇树科技展出了两款已量产的人形机器人Unitree G1、H1和两款四足机器狗亮相大会展区。Unitree G1于今年5月正式亮相，售价9.9万元。王兴兴称，售价9.9万元背后的思路是想让更多的人先把机器人用起来，不希望带头把行业做烂。他认为当前人形机器人整体市场价格还是偏高，最大的原因是技术成熟度没有机器狗高。
以下为王兴兴对话实录：

做机器人是顺势而为

澎湃科技：最近Figure AI也发布了第二代人形机器人视频，外媒评论说“硬件能力不够”，您怎么看？

王兴兴：整个人形机器人行业目前硬件和软件都还不够成熟，现在只能说是刚刚起步，但发展速度包括整体进展还算可以，没有特别好，但至少也没有特别坏。

澎湃科技：人形机器人、具身智能概念现在很火，但在早些时候，业界普遍不看好人形机器人，宇树做人形机器人的思路是怎样的？

王兴兴：雷总（雷军，小米科技创始人）说过要顺势而为，要追着社会潮流去做，如果做的太早或太晚，其实都是不好的。

2020年前，有很多投资人曾问我们做不做人形机器人，当时我非常斩钉截铁地回答“我们不做”，但为什么2023年初我们又开始做人形机器人了呢？

不做的最大原因是当时全球人形机器人的控制技术不是特别理想，性能上不去，看不到实用价值。但在2021年-2022年，在马斯克的带领下，全球科技对人形机器人非常关注，尤其是在2022年底大语言模型出来后，AI的技术有了质变，大家已经看到AI赋能机器人的潜力。

大家可能想不到，在2022年底，我们还没做人形机器人的时候，已经有一些客户找我们买人形机器人。所以我们觉得那个时候社会的共识、热度、客户对它的期待程度已经足够了，于是我们从2023年正式开始做人形机器人。

人形机器人市场热度远超行业成熟度

澎湃科技：行业内技术迭代的速度很快，你们做人形机器人有压力吗？

王兴兴：没有太大压力，我们做人形机器人是顺理成章的事情。原本我们只做机器狗，现在同样的人做两个产品，对公司来说反而是更好、更重要的一件事。机器狗和人形机器人的90%以上的硬件和软件都类似。目前人形机器人这个行业看似挺不错的。

技术迭代速度非常快，每周都有明显的技术进步。我们现阶段的产品主打还是在运动控制上，但工业场景也会做一些，不过目前工业有些场景不太好落地。

商业化方面我们确实不太着急，我们希望能把本体、产品本身做的更好时再推广。机器人行业完全是由技术驱动的，当你的技术能力越好，公司整体也会表现更好。

澎湃科技：你觉得现在人形机器人商业环境好吗？

王兴兴：有点过热，虽然说市场热度高，整个商业环境会好很多，但现在的市场热度远超行业实际的落地和商业化进展，因此会出现一些行业乱象，比如公司估值高、公司出现亏损、卷入价格战这些现象。

澎湃科技：今年国内外不少人形机器人进厂“打工”，你怎么看待？

王兴兴：进厂是一个趋势，近几个月，我们与蔚来等汽车工厂合作，部署了人形机器人进厂做搬运工作，国内友商也在推进类似合作。目前还处于试点阶段，虽然方向有价值，但还未实现商业闭环。一台机器人的成本仍高于人力，没能够形成正向循环的商业价值。我们并不集中在工业场景，科研、教育、AI公司和个人消费者，我们都完全欢迎。

机器人AI领域正处于探索阶段

澎湃科技：从目前人形机器人的研发角度看，大模型可以解决哪些技术问题？主要应用在哪些方向？大模型和人工智能的应用有望降低研发成本吗？

王兴兴： 目前大模型主要指大语言模型或多模态模型，这些技术确实能用于机器人，但这只是其中的一部分。真正的机器人大模型需要的不仅是语言能力，而是执行任务能力。比如，在工厂里工作的机器人完全可以不需要语言交流，通过照片、数字指令来完成任务。无论是在工厂拧螺丝、拆装，还是在家中做家务，机器人只要能完成任务，语言能力就是次要的。如果仅仅是对话功能，手机等设备就能做好了。

目前在“干活”这个点，大语言模型确实会用到一些部分，但更重要的是构建一个专门的机器人模型。这需要整合图像数据、关节指令、激光雷达数据等多种信息。最近特斯拉正在招募数据采集工人，这部分训练更多涉及模仿学习，与大语言模型的关联不大。此外，机器人模型的结构与大语言模型也存在差异，整体体系还不够成熟，机器人领域的数据采集、对齐和处理等方面的路径还不清晰。

在机器人智能领域，各家的技术路线差异很大。目前的路径并没有统一标准，很难判断哪个路线是正确的、哪个进展更快。现在的机器人研发有点像大语言模型发展前的一两年，大家意识到方向在哪里，但还没有能明确说自己的路径是绝对正确的。就像在GPT架构出现之前，有很多不同的语言模型结构，但后来大家发现GPT的架构更有价值，从而淘汰了其他模型。当前的机器人AI领域也正处于这样的探索阶段。

澎湃科技：目前人形机器人在你看来，有哪些待克服的卡点问题？

王兴兴：人形机器人目前面临的最大问题其实和大模型相似，整个机器人AI模型水平能力还不够，包括AI训练数据集、AI产品落地部署，还没有达到初代级GPT的水平，无论是四足机器人、清洁机器人还是其他类型的机器人，这是全球范围内的挑战。

从硬件的层面来说，目前也是不够的，虽然没有理论上的门槛，但工程上的问题是要把成本做得更低、外观做的更极致，硬件功能也更丰富，但硬件不是一个最大的限制。如果哪天有人把AI机器人的模型做出来，找宇树来定制机器人，我们可以保证年底之前直接给他做10万个人形机器人。

如果机器人的AI能力后期突破，达到某一临界点，它们会在工厂中实现高效率运行，机器人的价格也会更便宜，如果能超过人力的效率，商业上也可以大规模推广起来，这是最有价值的。

澎湃科技：你认为通用机器人领域何时会迎来“iPhone时刻”？ 

王兴兴：“iPhone时刻”是个关键节点， “iPhone时刻”的到来不是依赖单一技术突破，而是多个技术的综合性整合。我个人对于机器人AI领域持乐观态度，目前大家觉得机器人有点“傻”，只能做一些固定任务，但我认为未来的进展会很快。

我预计今年年底前，全球至少会有一家公司或实验室实现通用型机器人AI模型，但这还不能算是真正的“iPhone时刻”。我们期待的“iPhone时刻”是机器人在工业或服务业中有实际应用，且带动出货量大幅增长的那个节点。我认为，这个时刻可能需要3-4年，但不会超过5年。在工厂里实现大规模应用，估计还要两三年的时间。

不希望带头把行业做烂

澎湃科技：您如何看待当前智能机器人行业的竞争格局，像马斯克、小米等公司的投入，您认为中小公司的机会在哪里？

王兴兴： 中小公司的机会在于保持对前沿技术的敏锐度，预判未来1-5年的技术路线和产品趋势，并灵活布局，这样才能生存。相比之下，大公司反而受制于内部竞争、资源分配和复杂的沟通流程，反应速度往往不如中小公司。

澎湃科技：你认为未来机器人行业两三年的发展方向是什么？宇树是否会将未来业务All in到人形机器人赛道？

王兴兴： AI肯定是发展的大方向，但要看到底哪些AI的方向和渠道是正确的，现在行业很乱。我们对AI投入相对克制，因为太烧钱、烧人了。我们机器人的本体还是我们的立身之本，我其实非常感谢大家对我们的认可，无论是认可我们的硬件或认可我们的软件，我都非常感谢。

未来基于模仿学习这方面值得多关注，短期内还是相对能出成果，而且长期来看也比较有价值。特斯拉近期在招人做数据采集来做模仿学习。数据确实是一个卡点，要重新挖掘和生产数据。

我们并不会All in人形机器人，我们会四足机器人和人形机器人 “两条腿”走路，目前还是四足机器人卖的比较好。

澎湃科技：你们为什么会把价格控制在9.9万元？ 

王兴兴：我们价格低的原因很简单，因为做机器狗技术比较成熟，我们对发电机、机械结构传感器、电控系统芯片这些成本怎么控制，有较多的经验心得。我们的思路是想让更多的人先把机器人用起来，前提就得价格比较友好，太贵了买的人比较少。

目前，整体市场人形机器人价格目前偏高，毕竟技术成熟度没有机器狗高，成本还是会高一些。如果后续出货量增加，价格肯定会更加亲民。出货量增大以后，价格会降低，这也是所有产品发展的自然趋势。

我们不希望带头把这个行业做烂，我们还是希望价格相对合理，如果后续明年出货量提升、机器人的能力越来越强的话，我认为价格还是有更好的调整。
```

一样的嵌入文本之后，测试RAG效果：

![image-20240822115513523](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822115513523.png)

RAG回答失败了，这是因为我使用的模型参数太少了，还不够强大。如果你的电脑配置好，可以改用更智能的模型，如果你的电脑配置不好，可以选择混合使用的方式，即使用在线的对话模型Api，使用本地Ollama中的嵌入模型。

## 使用在线对话Api+本地Ollama嵌入模型体验SimpleRAG

appsettings.json可以这样写：

![image-20240822120347160](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822120347160.png)

测试RAG效果：

![image-20240822120526269](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822120526269.png)

RAG还是失败了。

模型换成meta-llama/Meta-Llama-3.1-8B-Instruct：

![image-20240822120706462](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822120706462.png)

模型换成google/gemma-2-9b-it：

![image-20240822121018509](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822121018509.png)

模型换成Qwen/Qwen2-72B-Instruct：

![image-20240822121616949](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822121616949.png)

通过源码找原因：

![image-20240822122700793](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822122700793.png)

将相关度调成0.3就可以找到相关文本了，但是感觉这样也会出问题，文档一多很容易找到不相关的文档，后面appsettings.json中会增加相关度的配置：

![image-20240822122749303](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822122749303.png)

现在再测试一下Qwen/Qwen2-7B-Instruct：

![image-20240822123253249](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822123253249.png)

也可以了。

对比不使用RAG的回答效果：

![image-20240822123617132](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/image-20240822123617132.png)

## 最后

如果对你有所帮助，点个Star✨，就是最大的支持😊。

如果您看了指南，还是遇到了问题，欢迎通过我的公众号联系我：

![](https://mingupupup.oss-cn-wuhan-lr.aliyuncs.com/imgs/qrcode_for_gh_eb0908859e11_344.jpg)